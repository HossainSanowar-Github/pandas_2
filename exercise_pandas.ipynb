{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c39a0987",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2112b677",
   "metadata": {},
   "source": [
    "# Series define can be possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a935bcf",
   "metadata": {},
   "source": [
    "1. list\n",
    "2. dict\n",
    "3. Math operation like using +, -, *, /\n",
    "4. can pass Numpy method: np.exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daa836d",
   "metadata": {},
   "source": [
    "# DataFrame\n",
    "\n",
    "can be define possible"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f6d1ef",
   "metadata": {},
   "source": [
    "1. numpy array\n",
    "2. series\n",
    "3. dict using multiple series, tuple, list,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff192a0",
   "metadata": {},
   "source": [
    "# Editing & Retrieving Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cc8c06",
   "metadata": {},
   "source": [
    "1. grab single column by `[]`\n",
    "2. grab multiple column by `[[]]`\n",
    "3. grab single row as a series by `loc` method\n",
    "4. grab cell of row and column by `loc` method\n",
    "5. grab multiple cells of rows and columns by `loc` method\n",
    "6. grab row by index position using `iloc`\n",
    "7. dataframe Math operation by `+,-,*,/`\n",
    "8. use `append` function\n",
    "9. Delecte row by `axis=0` using `drop` function\n",
    "10. Delete column by `axis=1`\n",
    "11. use `inplace=True`\n",
    "12. Create index by `set_index`\n",
    "13. Create reindex by `reset_index`\n",
    "14. Can be used `Assign` to create a column while leaving the original DF untouched\n",
    "15. `Combine` DataFrames while keeping df_3 data unless there is a NaN value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f93090",
   "metadata": {},
   "source": [
    "# Conditional Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9536cf6e",
   "metadata": {},
   "source": [
    "1. use conditional operators `>,<, >=,<=,<>,!=` or `gt,lt,ge,le,eq,ne` to retrieve a data based on the condition\n",
    "2. we can place conditions in brackets as well `bool_1=df>40, df[bool_1]`\n",
    "3. get bools for a column `df>40`\n",
    "4. Return a row if cell value matches a condition in column `df[df['E']>10]`\n",
    "5. we can focus on a column based on resulting dataframe  `df_1=df[df['E']>10], df_1['C']` or `df[df['E']>10]['C']`\n",
    "6. we can also grab multiple columns `df[df['E']>10][['C','D']]`\n",
    "7. we can use multiple conditions `&, |` like `df[(df['X']>3) | (df['Y']>5)]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c8e7a4",
   "metadata": {},
   "source": [
    "# File Input and Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d774eeff",
   "metadata": {},
   "source": [
    "1. Read csv, excel, json file\n",
    "2. Save csv, excel, json file by `.to_csv/excel`\n",
    "3. Read MySQL database\n",
    "4. Just get 1 column of data by using `usecols`\n",
    "example: `cs_df_st = pd.read_csv('ComputerSales.csv', usecols=[\"State\"], squeeze=True)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18725b68",
   "metadata": {},
   "source": [
    "# Basic and Math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded158ee",
   "metadata": {},
   "source": [
    "1. display 1st 5 rows `head()`\n",
    "2. display last 5 rows `tail()`\n",
    "3. display sample 5 rows `sample()`\n",
    "4. get 1st 2 rows `df[:2]`\n",
    "5. get 1st 5 rows by step 2 `df[:5:2]`, but for row and columns must be used `iloc` and `loc`\n",
    "6. get indexes `df.index.array`\n",
    "7. get numpy array `to_numpy`\n",
    "8. get array from series `ser.array`\n",
    "9. we can replace NaN values with 0 or anything else `df.fillna(0)`\n",
    "10. get values in row 2 `df.iloc[1]`\n",
    "11. we can can **add, sub, mul, and div** by `df.add(newdata, axis='columns')`, `df.sub(col, axis=0)`\n",
    "12. check if empty `df.empty`\n",
    "13. `Transform` executes a function on a dataframe `df.transform(lambda x: x+1)`\n",
    "14. we can `transform` using multiple functions `df.transform([lambda x: x**2, lambda x: x**3])`\n",
    "15. Passing a dictionary allows you to perform different calculations on different columns `df.transform({'A': lambda x: x**2, 'B': lambda x: x**3})`\n",
    "16. map performs a function on a series, map is iterable function: `df.map(lambda x: x**2)`\n",
    "17. applymap does the same on a dataframe `df.applymap(lambda x: x**2)`\n",
    "18. get unique in column by `df['A'].unique()`\n",
    "19. get number of uniques by `df.unique()`\n",
    "20. get number of value counts by `df.value_counts()`\n",
    "21. get columns name by `df.columns`\n",
    "22. get index info by `df.index`\n",
    "23. Return a DF that lists null values as True `df.isnull()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2989fba2",
   "metadata": {},
   "source": [
    "# Group Data\n",
    "\n",
    "Groupby allows you to group rows based on a columnand perform a function\n",
    "that combines those values (Aggregate Function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c788b5e",
   "metadata": {},
   "source": [
    "`dict_5 = {'Store': [1,2,1,2], 'Flavor': ['Choc', 'Van', 'Straw', 'Choc'], \n",
    "         'Sales': [26, 12, 18, 22]}\n",
    "df = pd.DataFrame(dict_5)`\n",
    "\n",
    "1. Group data by the column name like 'store number' example: `x=df.groupby('Store')`\n",
    "2. Get mean sales by store `x.mean()`\n",
    "3. Get sales total just for store 1 by `by_store.sum().loc[1]`\n",
    "4. we can use multiple functions of get a bunch by `x.describe()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0d26d5",
   "metadata": {},
   "source": [
    "# Concentrate, Merge, and Join"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c8538b",
   "metadata": {},
   "source": [
    "1. we can `concat` dfs in the order DFs are provided. `pd.concat([])`\n",
    "2. Merge 2 DFs using their shared `key column` like `pd.merge(df_12, df_13, how='inner', on='key')`\n",
    "    * how='left' or 'right' : Use keys from left or right \n",
    "    * how='outer' : Use union of keys\n",
    "3. `join` DFs with different indexes and instead of using `keys` use a column: `df_12.join(df_13, how='outer')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376f01dd",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c0b15a",
   "metadata": {},
   "source": [
    "1. get total count of both columns: count(),sum(skipna=True), mean(), median(), mode(),min(),max(),prod(),std(),var(),sem()#Standard error\n",
    "2. skew()#Negative : Left long tail, Positive : Right long tail\n",
    "3. kurt() #Kurtosis : < 3 less outliers, 3 Normal Distribution, > 3 more outliers\n",
    "4. quantile(0.5)\n",
    "5. cumsum(), cumprod(), cummax(), cummin()\n",
    "6. Multiple stats at once .describe()\n",
    "7. Count for each value in series\n",
    "8. ser_dice.value_counts()\n",
    "9. can perform calculations on multiple columns using aggregate `agg(np.mean)`\n",
    "10. can do this with multiple functions `df.agg(['mean', 'std'])`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f978ff38",
   "metadata": {},
   "source": [
    "# Iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2349b97",
   "metadata": {},
   "source": [
    "1. normal iteration for series like `for col in ser_7`\n",
    "2. `key, value` in df.items()\n",
    "3. `index, row` in df_8.iterrows()\n",
    "4. row in df_8.itertuples()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e82f9c",
   "metadata": {},
   "source": [
    "# Sorting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f4fa8d",
   "metadata": {},
   "source": [
    "1. df_8.sort_index(ascending=False)\n",
    "2. df_8.sort_values(by='E',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48485a9",
   "metadata": {},
   "source": [
    "# Passing Data to Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326b09cb",
   "metadata": {},
   "source": [
    "1. passing normal functon\n",
    "2. using `cut` function for creating groups\n",
    "3. we can use a `pipe` to pass a dataframe to multiple functions\n",
    "`cs_df.pipe(split_name).pipe(create_age_groups).head()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa21ef30",
   "metadata": {},
   "source": [
    "# Aligning, Reindexing and Renaming Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b409f05b",
   "metadata": {},
   "source": [
    "1. Series indexing by `df[:4], df[1:], df[1:5:2], df[:]`\n",
    "2. Align with both series using `left, right, inner`\n",
    "3. we can also align used in dataframe\n",
    "4. reindex align for series and dataframe\n",
    "5. drop, rename "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8330d0cc",
   "metadata": {},
   "source": [
    "# Multi_Index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e005f93d",
   "metadata": {},
   "source": [
    "1. create multi_indexing\n",
    "2. create pivot table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1d5d7e",
   "metadata": {},
   "source": [
    "# Handling Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcdef9e",
   "metadata": {},
   "source": [
    "1. Drops rows with missing values by `df_10.dropna()`\n",
    "2. Drop all columns with missing data, `df_10.dropna(axis=1)`\n",
    "3. Drop row unless it has at least 2 non-NaN values `df_10.dropna(thresh=2)`\n",
    "4. Fill NaN values with 0 `df_10.fillna(value=0)`\n",
    "5. Fill `A` column with the mean of column: `df_10['A'].fillna(value=df_10['A'].mean())`\n",
    "6. Fill with previous value `df_10.fillna(method='ffill')`\n",
    "7. Fill with next value (Only works if there is a next value) `df_10.fillna(method='bfill')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92644e44",
   "metadata": {},
   "source": [
    "# Experiment with Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "01a07ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Sale ID', 'Contact', 'Sex', 'Age', 'State', 'Product ID',\n",
      "       'Product Type', 'Sale Price', 'Profit', 'Lead', 'Month', 'Year'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    35\n",
       "True      4\n",
       "Name: Profit, dtype: int64"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ComputerSales.csv')\n",
    "cs_df.head() # Get 1st 5\n",
    "print(cs_df.columns) # Get column names\n",
    "cs_df['Profit'].mean() # Average profit per item\n",
    "# Get the product with the highest profit\n",
    "cs_df[['Product ID', 'Profit']].max(axis=0).head()\n",
    "# Number of people who purchased from WV\n",
    "cs_df[cs_df['State']=='WV']['State'].count()\n",
    "# Number of purchases in 2019\n",
    "len(cs_df[cs_df['Year']==2019].index)\n",
    "# Get number of sales for each product type\n",
    "cs_df['Product ID'].value_counts()\n",
    "# Get list of customers that bought a specific product\n",
    "cs_df[cs_df['Product ID']=='M01-F0024']['Contact']\n",
    "# How many made a website purchase for a profit over $200\n",
    "cs_df[(cs_df['Lead']=='Website') & (cs_df['Profit']>150)]['Lead'].count()\n",
    "# Find out how many product profit amounts include .89 in cents\n",
    "cs_df['Profit'].apply(lambda cents: str(cents).split('.')[1]=='89').value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8380f9e",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b615960",
   "metadata": {},
   "source": [
    "1. hist, plot, plot.bar(), scatter(), pie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d117fe77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
